{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pylab\n",
    "# pylab.rcParams['figure.figsize'] = (10, 5)\n",
    "import matplotlib as mpl\n",
    "# mpl.rcParams['figure.dpi'] = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt \n",
    "\n",
    "# Better to avoid inline mode, as the particles are quite small most of the times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 : Get the scale, if you don't already know it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tem_scale(img_path,y1=None,y2=None,x1=None,x2=None, threshold_type = cv2.THRESH_BINARY,lower_thresh = 220):\n",
    "    \n",
    "    '''\n",
    "    This function takes in an image and tries to find the scale by measuring the line segment usually given at the bottom left \n",
    "    if the TEM micrograph. It approximates a rectangle for this and reports the width of rectangle as the scale.\n",
    "    \n",
    "    Parameters:\n",
    "    img_path :  Path of the TEM image.\n",
    "    y1 = start index for cropping along vertical axis, must be an integer.\n",
    "    y2 = end index for cropping along vertical axis, must be an integer.\n",
    "    x1 = start index for cropping along horizontal axis, must be an integer.\n",
    "    x2 = end index for cropping along horizontal axis, must be an integer.\n",
    "    \n",
    "    Prints width of the approximating rectangle. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    if np.any(img):\n",
    "        pass\n",
    "    else:\n",
    "        print('Image could not be read, check path or check if image is corrupt.')\n",
    "        return None\n",
    "    \n",
    "    if y1 == None:\n",
    "        y1 = int(0.80*img.shape[0])\n",
    "    if y2 == None:\n",
    "        y2 = int(0.95*img.shape[0])\n",
    "    if x1 == None:\n",
    "        x1 = 0\n",
    "    if x2 == None:\n",
    "        x2 = int(0.5*img.shape[1])\n",
    "    \n",
    "    crop_img = img[y1:y2,0:x2]\n",
    "    \n",
    "    if np.any(crop_img):\n",
    "        pass\n",
    "    else:\n",
    "        print('Cropped Image is empty, check crop dimensions.')\n",
    "        \n",
    "    cv2.imshow('cropped',crop_img)\n",
    "    scale_gray = cv2.cvtColor(crop_img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # choose threshold type  as cv2.THRESH_BINARY_INV if scale region is black.\n",
    "    if threshold_type == cv2.THRESH_BINARY_INV:\n",
    "        lower_thresh = 0\n",
    "    ret, thresh = cv2.threshold(scale_gray, lower_thresh, 255, threshold_type)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # filter noisy detection\n",
    "    contours = [c for c in contours if cv2.contourArea(c) > 300]\n",
    "    contours.sort(key=lambda c: (cv2.boundingRect(c)[1], cv2.boundingRect(c)[0]))\n",
    "    cv2.rectangle(crop_img, cv2.boundingRect(contours[-1]), (0,255,0), 2)\n",
    "    x,y,w,h = cv2.boundingRect(contours[-1])\n",
    "    print('x : %f , y = %f , w = %f , h = %f '%(x,y,w,h))\n",
    "    print('The width in pixels is : ',w)\n",
    "    cv2.imshow('scale_marked',crop_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Find all features, irrespective of size and generate contours by thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_particles(img_path,scale=None,thresh = 45,save_images = False):\n",
    "    \n",
    "    '''\n",
    "    This function finds particles by contouring, Image which is loade converted to grayscale.\n",
    "    A gaussian Blur is then used to remove a bit of noise in the images, which helps with over-detection.\n",
    "    Threshold style by default is cv2.THRESH_BINARY.\n",
    "    \n",
    "    Threshold by default is 45. Change this according to your data.\n",
    "    \n",
    "    Parameters:\n",
    "    img_path :  Path of the TEM image.\n",
    "    scale : Either already known or found from get_tem_scale()\n",
    "    thresh :  lower limit of threshold.\n",
    "    save_images : If true, the images are saved to same directory as the original images, False by default.\n",
    "    \n",
    "    '''\n",
    "    # Read the image\n",
    "    img = cv2.imread(img_path)\n",
    "    if np.any(img):\n",
    "        pass\n",
    "    else:\n",
    "        print('Image could not be read, check path or check if image is corrupt.')\n",
    "        return None\n",
    "    \n",
    "    #img = cv2.resize(img,(0,0),fx=0.25,fy=0.25)\n",
    "    \n",
    "    # Gaussian Blur ot reduce noise\n",
    "    img = cv2.GaussianBlur(img,(5,5),0)\n",
    "    \n",
    "    # convert to grascale\n",
    "    gray= cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # thresholding, making a binary image.\n",
    "    ret,thresh = cv2.threshold(gray,thresh,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    #img_thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,1151,1)\n",
    "    cv2.namedWindow(\"Threshold image\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('Threshold image',thresh)\n",
    "    contours,hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    img2 = img.copy()\n",
    "    \n",
    "    index = -1\n",
    "    thickness = 1\n",
    "    color = (255,0,255)\n",
    "    \n",
    "    # drawing contours.\n",
    "    cv2.drawContours(img2,contours,index,color,thickness)\n",
    "    cv2.namedWindow(\"contours\", cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    cv2.imshow('contours',img2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # saving images\n",
    "    if save_images==True:\n",
    "        cv2.imwrite(img_path+'_thresh.tif',thresh)\n",
    "        cv2.imwrite(img_path+'_contours.tif',img2)\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Plot the size distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_distribution_plot(img_path,contours=None,scale=None,r_min=None,r_max=None, bins=None, save_fig = False):\n",
    "    \n",
    "    '''\n",
    "    This generates a size ditribtution plot, the sizes can be managed by r_min and r_max.\n",
    "    \n",
    "    Parameters : \n",
    "    img_path :  Path of the TEM image.\n",
    "    contours: Obatained from find_particles()\n",
    "    scale : Already known or found from get_tem_scale()\n",
    "    r_min :  Minimum radius of particles to be marked. By default, it is equal to scale.\n",
    "    r_max = Maximum radius of particles to be marked. By default, it is 100 times the scale.\n",
    "    bins :  bins in the histogram which is plotted.\n",
    "    \n",
    "    Prints the mean particles size. (Note that the diameters are returned.)\n",
    "    If you want to exclude all particles under 10 nm, give r_max as 5.\n",
    "    Returns an array of particle sizes.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Change this according to your data.\n",
    "    if r_min == None:\n",
    "        r_min = 0.5*scale\n",
    "    if r_max == None:\n",
    "        r_max = 50*scale\n",
    "    #######\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    if np.any(img):\n",
    "        pass\n",
    "    else:\n",
    "        print('Image could not be read, check path or check if image is corrupt.')\n",
    "        return None\n",
    "    \n",
    "    fig,ax = plt.subplots(1,2,figsize=(10,5))\n",
    "    ax[0].imshow(img)\n",
    "    ax[1].imshow(img)\n",
    "    sizes = []\n",
    "   \n",
    "    for i in range(len(contours)):\n",
    "        cnt = contours[i]\n",
    "        (x,y),radius = cv2.minEnclosingCircle(cnt)\n",
    "        center = (int(x),int(y))\n",
    "        radius=int(radius)\n",
    "        if radius > r_min*scale and radius < r_max*scale:\n",
    "            sizes.append(radius)\n",
    "            c=plt.Circle((x,y),radius,color='r' ,linewidth=0.3, fill=False)\n",
    "            \n",
    "            # commented out in case of a lot of particles, it is a very messy plot.\n",
    "            #ax[1].annotate(str(i),(x,y))   \n",
    "            \n",
    "            ax[1].add_patch(c)\n",
    "    sizes = (np.array(sizes)*2)/scale # Note that these are diameters \n",
    "    fig1,ax1 = plt.subplots()\n",
    "    if bins == None:\n",
    "        bins = len(set(sizes))\n",
    "    \n",
    "    ax1.hist(sizes,color='#98ff98', histtype='bar', ec='black', bins=bins)\n",
    "    \n",
    "    plt.xlabel('Diameter (nm)')\n",
    "    plt.ylabel('Number of particles')\n",
    "    print('Mean diameter : %0.2f'%(np.mean(sizes)))\n",
    "    print('Total Particles : %g'%(len(sizes)))\n",
    "    \n",
    "    if save_fig == True:\n",
    "        plt.savefig(img_path+'_analysis.png')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return np.sort(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
